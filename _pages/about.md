---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>
Hi! I am a second-year PhD student in Computer Science at National University of Singapore advised by [Yang You](https://www.comp.nus.edu.sg/~youy/), where I also completed my master's studies. I obtained my bachelor's degree in CS & EE from Huazhong University of Science and Technology. I currently intern at [Adobe](https://www.adobe.com/) with [Yan Kang](https://research.adobe.com/person/yan-kang/). Previously, I collaborated at [Pika](https://pika.art/about) with [Chenlin Meng](https://cs.stanford.edu/~chenlin/) and interned at [Colossal-AI](https://github.com/hpcaitech/ColossalAI) with [Jiarui Fang](https://fangjiarui.github.io/).

My current research mainly focuses on **efficient and scalable machine learning** through algorithm and infrastructure co-optimization, recently with a primary emphasis on **efficient video generation**.

I am always happy to chat about interesting research ideas, and looking for academic collaborations and interns. Please drop me an email if you are interested in collaborating with me.


# üî• News
- *2024.03*: üéâ Two papers are accepted by ICLR 2024
- *2023.05*: üéâ Five papers are accepted by ACL 2023
- *2023.01*: DiffSinger was introduced in [a very popular video](https://www.bilibili.com/video/BV1uM411t7ZJ) (2000k+ views) in Bilibili!
- *2023.01*: I join TikTok <img src='./images/tiktok.png' style='width: 6em;'> as a speech research scientist in Singapore!
- *2022.02*: I release a modern and responsive academic personal [homepage template](https://github.com/RayeRen/acad-homepage.github.io). Welcome to STAR and FORK!


# üìù Selected Publications ([all](https://scholar.google.com/citations?user=I5NBOacAAAAJ))
## üìΩÔ∏è Efficient Video Generation
<ul>
  <li>
    <code class="language-plaintext highlighter-rouge">ICLR 2025</code> <strong>Real-Time Video Generation with Pyramid Attention Broadcast</strong>
    <div style="display: inline">
        <a href="https://arxiv.org/abs/2408.1258"> [paper]</a>
        <a href="https://github.com/NUS-HPC-AI-Lab/VideoSys"> [code]</a>
        <a href="https://oahzxl.github.io/PAB/"> [blog]</a>
    </div>
    <img src='https://img.shields.io/github/stars/NUS-HPC-AI-Lab/VideoSys.svg?style=social&label=Star' alt="sym" height="90%">
    <div><i><u>Xuanlei Zhao</u><b><sup>*</sup></b>, Xiaolong Jin<b><sup>*</sup></b>, Kai Wang<b><sup>*</sup></b>, Yang You</i></div>
  </li>
  <li>
    <code class="language-plaintext highlighter-rouge">ICML 2025</code> <strong>DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers</strong>
    <div style="display: inline">
        <a href="https://arxiv.org/abs/2403.10266"> [paper]</a>
        <a href="https://github.com/NUS-HPC-AI-Lab/VideoSys"> [code]</a>
    </div>
    <div><i><u>Xuanlei Zhao</u>, Shenggan Cheng, Chang Chen, Zangwei Zheng, Ziming Liu, Zheming Yang, Yang You</i></div>
  </li>
</ul>

## üßπ Efficient Memory Cost
<ul>
  <li>
    <code class="language-plaintext highlighter-rouge">ICLR 2024</code> <strong>AutoChunk: Automated Activation Chunk for Memory-Efficient Long Sequence Inference</strong>
    <div style="display: inline">
        <a href="https://arxiv.org/abs/2401.10652"> [paper]</a>
        <a href="https://github.com/hpcaitech/ColossalAI/tree/main/colossalai/autochunk"> [code]</a>
    </div>
    <div><i><u>Xuanlei Zhao</u>, Shenggan Cheng, Guangyang Lu, Jiarui Fang, Haotian Zhou, Bin Jia, Ziming Liu, Yang You</i></div>
  </li>
  <li>
    <code class="language-plaintext highlighter-rouge">MLSys 2024</code> <strong>HeteGen: Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices</strong>
    <div style="display: inline">
        <a href="https://arxiv.org/abs/2403.01164"> [paper]</a>
    </div>
    <div><i><u>Xuanlei Zhao</u><b><sup>*</sup></b>, Bin Jia<b><sup>*</sup></b>, Haotian Zhou<b><sup>*</sup></b>, Ziming Liu, Shenggan Cheng, Yang You</i></div>
  </li>
</ul>

## üî¨ Efficient AI for Science
<ul>
  <li>
    <code class="language-plaintext highlighter-rouge">PPoPP 2024</code> <strong>FastFold: Optimizing AlphaFold Training and Inference on GPU Clusters</strong>
    <div style="display: inline">
        <a href="https://dl.acm.org/doi/10.1145/3627535.3638465"> [paper]</a>
        <a href="https://github.com/hpcaitech/FastFold"> [code]</a>
    </div>
    <img src='https://img.shields.io/github/stars/hpcaitech/FastFold.svg?style=social&label=Star' alt="sym" height="90%">
    <div><i>Shenggan Cheng, <u>Xuanlei Zhao</u>, Guangyang Lu, Jiarui Fang, Tian Zheng, Ruidong Wu, Xiwen Zhang, Jian Peng, Yang You</i></div>
  </li>
</ul>

## Others
- `NeurIPS 2023` [Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective](https://openreview.net/forum?id=Rp4PA0ez0m), Pengfei Wei, Lingdong Kong, Xinghua Qu, **Yi Ren**, et al.
- ``ACM-MM 2022`` [Video-Guided Curriculum Learning for Spoken Video Grounding](), Yan Xia, Zhou Zhao, Shangwei Ye, Yang Zhao, Haoyuan Li, **Yi Ren**


# üéñ Honors and Awards
- *2021.10* Tencent Scholarship (Top 1%)
- *2021.10* National Scholarship (Top 1%)
- *2020.12* [Baidu Scholarship](https://baike.baidu.com/item/%E7%99%BE%E5%BA%A6%E5%A5%96%E5%AD%A6%E9%87%91/9929412) (10 students in the world each year)
- *2020.12* [AI Chinese new stars](https://mp.weixin.qq.com/s?__biz=MzA4NzQ5MTA2NA==&mid=2653639431&idx=1&sn=25b6368c1954419b9090840347d9a27d&chksm=8be75b90bc90d286a5af3ef8e610e822d705dc3cf4382b45e3f14489f3e7ec4fd8c95ed0eceb&mpshare=1&scene=2&srcid=0511LMlj9Qv9DeIZAjMjYAU9&sharer_sharetime=1620731348139&sharer_shareid=631c113940cb81f34895aa25ab14422a#rd) (100 worldwide each year)
- *2020.12* [AI Chinese New Star Outstanding Scholar](https://mp.weixin.qq.com/s?__biz=MzA4NzQ5MTA2NA==&mid=2653639431&idx=1&sn=25b6368c1954419b9090840347d9a27d&chksm=8be75b90bc90d286a5af3ef8e610e822d705dc3cf4382b45e3f14489f3e7ec4fd8c95ed0eceb&mpshare=1&scene=2&srcid=0511LMlj9Qv9DeIZAjMjYAU9&sharer_sharetime=1620731348139&sharer_shareid=631c113940cb81f34895aa25ab14422a#rd) (10 candidates worldwide each year)
- *2020.12* [ByteDance Scholars Program](https://ur.bytedance.com/scholarship) (10 students in China each year)
- *2020.10* Tianzhou Chen Scholarship (Top 1%)
- *2020.10* National Scholarship (Top 1%)
- *2015.10* National Scholarship (Undergraduate) (Top 1%)


# üìñ Educations
- *2019.06 - 2022.04*, Master, Zhejiang University, Hangzhou.
- *2015.09 - 2019.06*, Undergraduate, Chu Kochen Honors College, Zhejiang Univeristy, Hangzhou.
- *2012.09 - 2015.06*, Luqiao Middle School, Taizhou.


# üí¨ Invited Talks
- *2022.02*, Hosted MLNLP seminar \| [\[Video\]](https://www.bilibili.com/video/BV1wF411x7qh)
- *2021.06*, Audio & Speech Synthesis, Huawei internal talk
- *2021.03*, Non-autoregressive Speech Synthesis, PaperWeekly & biendata \| [\[video\]](https://www.bilibili.com/video/BV1uf4y1t7Hr/)
- *2020.12*, Non-autoregressive Speech Synthesis, Huawei Noah's Ark Lab internal talk


# üíª Internships
- *2021.06 - 2021.09*, Alibaba, Hangzhou.
- *2019.05 - 2020.02*, [EnjoyMusic](https://enjoymusic.ai/), Hangzhou.
- *2019.02 - 2019.05*, [YiWise](https://www.yiwise.com/), Hangzhou.
- *2018.08 - 2019.02*, [MSRA, machine learning Group](https://www.microsoft.com/en-us/research/group/machine-learning-research-group/), Beijing.
- *2018.01 - 2018.06*, [NetEase, AI department](https://hr.163.com/zc/12-ai/index.html), Hangzhou.
- *2017.08 - 2018.12*, DashBase (acquired by [Cisco](https://blogs.cisco.com/news/349511)), Hangzhou.
