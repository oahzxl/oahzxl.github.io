
# üìù Publications 

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2019</div><img src='images/fs.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FastSpeech: Fast, Robust and Controllable Text to Speech](https://papers.nips.cc/paper/8580-fastspeech-fast-robust-and-controllable-text-to-speech.pdf) \\
**Yi Ren**, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu

[**Project**](https://speechresearch.github.io/fastspeech/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- FastSpeech is the first fully parallel end-to-end speech synthesis model.
- **Academic Impact**: This work is included by many famous speech synthesis open-source projects, such as [ESPNet ![](https://img.shields.io/github/stars/espnet/espnet?style=social)](https://github.com/espnet/espnet). Our work are promoted by more than 20 media and forums, such as [Êú∫Âô®‰πãÂøÉ](https://mp.weixin.qq.com/s/UkFadiUBy-Ymn-zhJ95JcQ)„ÄÅ[InfoQ](https://www.infoq.cn/article/tvy7hnin8bjvlm6g0myu).
- **Industry Impact**: FastSpeech has been deployed in [Microsoft Azure TTS service](https://techcommunity.microsoft.com/t5/azure-ai/neural-text-to-speech-extends-support-to-15-more-languages-with/ba-p/1505911) and supports 49 more languages with state-of-the-art AI quality. It was also shown as a text-to-speech system acceleration example in [NVIDIA GTC2020](https://resources.nvidia.com/events/GTC2020s21420).
</div>
</div> -->

## üìΩÔ∏è Efficient Video Generation
<ul>
  <li>
    <code class="language-plaintext highlighter-rouge">ICLR 2025</code> <strong>Real-Time Video Generation with Pyramid Attention Broadcast</strong>
    <div style="display: inline">
        <a href="https://arxiv.org/abs/2408.1258"> [paper]</a>
        <a href="https://github.com/NUS-HPC-AI-Lab/VideoSys"> [code]</a>
        <a href="https://oahzxl.github.io/PAB/"> [blog]</a>
    </div>
    <img src='https://img.shields.io/github/stars/NUS-HPC-AI-Lab/VideoSys.svg?style=social&label=Star' alt="sym" height="90%">
    <div><i><u>Xuanlei Zhao</u><b><sup>*</sup></b>, Xiaolong Jin<b><sup>*</sup></b>, Kai Wang<b><sup>*</sup></b>, Yang You</i></div>
  </li>
  <li>
    <code class="language-plaintext highlighter-rouge">ICML 2025</code> <strong>DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers</strong>
    <div style="display: inline">
        <a href="https://arxiv.org/abs/2403.10266"> [paper]</a>
        <a href="https://github.com/NUS-HPC-AI-Lab/VideoSys"> [code]</a>
    </div>
    <div><i><u>Xuanlei Zhao</u>, Shenggan Cheng, Chang Chen, Zangwei Zheng, Ziming Liu, Zheming Yang, Yang You</i></div>
  </li>
</ul>

## üßπ Efficient Memory Cost
<ul>
  <li>
    <code class="language-plaintext highlighter-rouge">ICLR 2024</code> <strong>AutoChunk: Automated Activation Chunk for Memory-Efficient Long Sequence Inference</strong>
    <div style="display: inline">
        <a href="https://arxiv.org/abs/2401.10652"> [paper]</a>
        <a href="https://github.com/hpcaitech/ColossalAI/tree/main/colossalai/autochunk"> [code]</a>
    </div>
    <div><i><u>Xuanlei Zhao</u>, Shenggan Cheng, Guangyang Lu, Jiarui Fang, Haotian Zhou, Bin Jia, Ziming Liu, Yang You</i></div>
  </li>
  <li>
    <code class="language-plaintext highlighter-rouge">MLSys 2024</code> <strong>HeteGen: Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices</strong>
    <div style="display: inline">
        <a href="https://arxiv.org/abs/2403.01164"> [paper]</a>
    </div>
    <div><i><u>Xuanlei Zhao</u><b><sup>*</sup></b>, Bin Jia<b><sup>*</sup></b>, Haotian Zhou<b><sup>*</sup></b>, Ziming Liu, Shenggan Cheng, Yang You</i></div>
  </li>
</ul>

## üî¨ Efficient AI for Science
<ul>
  <li>
    <code class="language-plaintext highlighter-rouge">PPoPP 2024</code> <strong>FastFold: Optimizing AlphaFold Training and Inference on GPU Clusters</strong>
    <div style="display: inline">
        <a href="https://dl.acm.org/doi/10.1145/3627535.3638465"> [paper]</a>
        <a href="https://github.com/hpcaitech/FastFold"> [code]</a>
    </div>
    <img src='https://img.shields.io/github/stars/hpcaitech/FastFold.svg?style=social&label=Star' alt="sym" height="90%">
    <div><i>Shenggan Cheng, <u>Xuanlei Zhao</u>, Guangyang Lu, Jiarui Fang, Tian Zheng, Ruidong Wu, Xiwen Zhang, Jian Peng, Yang You</i></div>
  </li>
</ul>

## Others
- `NeurIPS 2023` [Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective](https://openreview.net/forum?id=Rp4PA0ez0m), Pengfei Wei, Lingdong Kong, Xinghua Qu, **Yi Ren**, et al.
- ``ACM-MM 2022`` [Video-Guided Curriculum Learning for Spoken Video Grounding](), Yan Xia, Zhou Zhao, Shangwei Ye, Yang Zhao, Haoyuan Li, **Yi Ren**