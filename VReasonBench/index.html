<!DOCTYPE html>
<html>
<meta property='og:title' content='V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models'/>
<meta property='og:description' content='V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models'/>
<meta property='og:url' content='https://oahzxl.github.io/Enhance_A_Video/'/>
<meta property='og:image:width' content='1200' />
<meta property='og:image:height' content='663' />
<!-- TYPE BELOW IS PROBABLY: 'website' or 'article' or look on https://ogp.me/#types -->
<meta property="og:type" content='website'/>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models">
  <meta name="keywords" content="V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models</title>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/tab_gallery.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="juxtapose/css/juxtapose.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/magnifier.js"></script>
  <link href="https://fonts.cdnfonts.com/css/menlo" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/image_card_fader.css">
  <link rel="stylesheet" href="./static/css/image_card_slider.css">
  <link rel="stylesheet"
        href="https://fonts.googleapis.com/css?family=Patrick+Hand|Google+Sans|Noto+Sans|Castoro|Lato|Open+Sans&effect=shadow-multiple|emboss|3d"> 
  <!-- <link rel="icon" href="./static/images/pyramid.png" type="image/x-icon"> -->
  <!-- <link rel="shortcut icon" href="./static/images/pyramid.png" type="image/x-icon"> -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/tab_gallery.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="juxtapose/css/juxtapose.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/magnifier.js"></script>
  <link href="https://fonts.cdnfonts.com/css/menlo" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/image_card_fader.css">
  <link rel="stylesheet" href="./static/css/image_card_slider.css">
</head>

<style>
  @import url('https://fonts.cdnfonts.com/css/menlo');

  .video-table td, .video-table th {
    padding-top: 2px;
    padding-bottom: 2px;
    padding-left: 4px;
    padding-right: 4px;
    font-weight: normal;
  }
  .first-col {
    width: 7%;
    vertical-align: middle;
  }
  .other-col {
    width: 31%;
  }
  body {
    font-family: "Lato", sans-serif;
    font-size: 1.1em;
  }
  .title.is-3 {
    font-weight: 900;
    font-size: 2.0rem;
  }
  .title.is-4 {
    font-weight: 700;
    font-size: 1.7rem;
  }
  .custom-emoji {
    width: 1em;
    height: 1em;
    display: inline-block;
    background-image: url('./static/images/pyramid.png');
    background-size: cover;
    vertical-align: middle;
    line-height: 1;
  }

  .interpolation-video {
    width: 100%;
    height: auto;
    border-radius: 5px;
  }
  
  .results-carousel .item {
    margin: 10px;
    overflow: hidden;
    padding: 20px;
    font-size: 0;
  }
  
  .results-carousel video {
    margin: 0;
  }

</style>


<body>
  <section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <br><br>
          <h1 class="title is-2 publication-title" style="font-size: 1.95rem">
            V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models
          </h1>
          

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yangluo7.github.io/" target="_blank">Yang Luo</a><sup>1,2*</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://oahzxl.github.io/" target="_blank">Xuanlei Zhao</a><sup>2*</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="baijiong-lin.github.io" target="_blank">Baijiong Lin</a><sup>1,3*</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://advocate99.github.io/" target="_blank">Lingting Zhu</a><sup>1,4</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://github.com/LiyaoTang" target="_blank">Liyao Tang</a><sup>1,5</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://liuricky.github.io/" target="_blank">Yuqi Liu</a><sup>1,6</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://www.yingcong.me/" target="_blank">Ying-Cong Chen</a><sup>3</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="http://thesouthfrog.com/about.me/" target="_blank">Shengju Qian</a><sup>6</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=2Z1GJ50AAAAJ&hl=en" target="_blank">Xin Wang</a><sup>1</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://www.comp.nus.edu.sg/~youy/" target="_blank">Yang You</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tencent&nbsp;&nbsp;</span>
            <span class="author-block"><sup>2</sup>National University of Singapore&nbsp;&nbsp;</span>
            <span class="author-block"><sup>3</sup>The Hong Kong University of Science and Technology (Guangzhou)&nbsp;&nbsp;</span>
            <span class="author-block"><sup>4</sup>The University of Hong Kong&nbsp;&nbsp;</span>
            <span class="author-block"><sup>5</sup>The University of Sydney</span>
            <span class="author-block"><sup>6</sup>The Chinese University of Hong Kong</span>
          </div>

          <!-- <div class="is-size-5 publication-authors">
            {xuanlei, kai.wang, youy}@comp.nus.edu.sg&nbsp;&nbsp;&nbsp;jin509@purdue.edu
          </div> -->

          <div class="is-size-5 publication-authors">
            (* indicates equal contribution)
          </div>

          <!-- <div class="is-size-5 publication-venue">
            in XXX
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Code Link. -->
              <span class="link-block">
                <a href="" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- paper -->
              <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- doc -->
              <!-- <span class="link-block">
                <a href="https://github.com/NUS-HPC-AI-Lab/VideoSys/blob/master/docs/pab.md" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-book"></i>
                  </span>
                  <span>Doc</span>
                  </a>
              </span> -->
              <!-- twitter -->
              <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-twitter"></i>
                  </span>
                  <span>Twitter</span>
                </a>
              </span>
              <!-- bibtex -->
              <span class="link-block">
                <a href="#bibtex"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-obp"></i>
                  </span>
                  <span>BibTex</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">

        <div class="content has-text-centered">
          <img src="./static/images/overview.png" style="width: 100%;">
        </div>
        <div class="content has-text-justified">
          <p>
            Main Contributions:
            <ul>
              <li>111.</li>
              <li>222.</li>
              <li>333.</li>
            </ul>
          </p>
          <p>
            We introduce V-ReasonBench, a benchmark designed to assess video reasoning across four key dimensions: structured problem-solving, spatial cognition, pattern-based inference, and physical dynamics. The benchmark is built from both synthetic and real-world image sequences and provides a diverse set of answer-verifiable tasks that are reproducible, scalable, and unambiguous. Evaluations of six state-of-the-art video models reveal clear dimension-wise differences, with strong variation in structured, spatial, pattern-based, and physical reasoning. We further compare video models with strong image models, analyze common hallucination behaviors, and study how video duration affects Chain-of-Frames reasoning. Overall, V-ReasonBench offers a unified and reproducible framework for measuring video reasoning and aims to support the development of models with more reliable, human-aligned reasoning skills.
          </p>
        </div>

        <h2 class="title is-3">Results of Recent Video Generation Models</h2>
        <div class="content has-text-centered">
          <img src="./static/images/result.png" style="width: 60%;">
        </div>
        <p>
          Model-level overall and per-dimension performance on V-ReasonBench. A pass@5 score for each model is calculated within each dimension and presented accordingly.
        </p>
        <div class="content has-text-centered">
          <img src="./static/images/result2.png" style="width: 60%;">
        </div>
        <p>
          Summary of V-ReasonBench performance across video models. The figure illustrates how six video generation models perform on 13 reasoning tasks, with scores rescaled within each dimension to enable direct comparison.
        </p>

        <h2 class="title is-3">Reasoning Task Coverage and Video Totals</h2>
        <div class="content has-text-centered">
          <img src="./static/images/task.png" style="width: 60%;">
        </div>
        <p>
          Overview of reasoning dimensions, tasks, and number of videos in V-ReasonBench. Each instance is an initial–final image pair, with each model generating five videos for pass@5 evaluation.
        </p>

        <h2 class="title is-3">Precise and Reliable Evaluation</h2>
        <div class="content has-text-centered">
          <img src="./static/images/eval1.png" style="width: 60%;">
        </div>
        <p>
          Example failure case from Sequence Completion task illustrating the limitations of VLM-based automatic evaluation. Although the underlying rule is simple, the VLM incorrectly assesses the model's output due to difficulties in recognizing small grid cells and fine structural differences.
        </p>
        <div class="content has-text-centered">
          <img src="./static/images/eval2.png" style="width: 60%;">
        </div>
        <p>
          Human–alignment validation of our benchmark's scoring pipeline. Each point compares binary Pass/Unpass decisions from the automatic evaluation with human judgments across six reasoning categories.
        </p>

        <h2 class="title is-3">Reasoning Patterns in Video Generation</h2>
        <div class="content has-text-centered">
          <img src="./static/images/pattern.png" style="width: 60%;">
        </div>
        <p>
          Example from the Seedance-1.0-Lite model on the horizontal visual symmetry task. The model introduces additional decorative patterns across the mirrored axis, illustrating its tendency to enrich visual appearance rather than preserve original geometric form.
        </p>

        <h2 class="title is-3">Influence of Duration on Video Reasoning</h2>
        <div class="content has-text-centered">
          <img src="./static/images/duration.png" style="width: 60%;">
        </div>
        <p>
          Effect of video duration on reasoning outcomes of Sora2 in the Chain-of-Frame setting. Each row compares model generations with different “thinking” durations for tasks such as Sudoku and Rule Following. Although longer durations correspond to longer reasoning processes (4s vs. 8s, 5s vs. 10s), the resulting outputs do not consistently improve.
        </p>

        <h2 class="title is-3">Video Models vs. Image Models</h2>
        <div class="content has-text-centered">
          <img src="./static/images/vs.png" style="width: 60%;">
        </div>
        <p>
          Comparison between Veo-3.1 (video model) and NanoBanana (image model) on Block Sliding (left) and Code Execution (right). Video models leverage the Chain-of-Frames process to simulate intermediate states, enabling stronger performance on tasks that require causal or temporal reasoning, although intermediate transitions may still appear physically inconsistent. Image models provide clean and stable outputs and excel at text-based tasks such as code execution, but their single-frame reasoning limits their ability to capture the underlying physical dynamics.
        </p>

        <h2 class="title is-3">Hallucination in Video Reasoning</h2>
        <div class="content has-text-centered">
          <img src="./static/images/hall.png" style="width: 60%;">
        </div>
        <p>
          Examples of hallucinations in the Chain-of-Frame reasoning process. Each row shows a trajectory from input to output, where the final frame is correct but intermediate frames display unrealistic or physically inconsistent transitions.
        </p>

      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="container is-max-desktop hero-body">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Evaluations</h2>
        
        <h2 class="title is-4">Qualitative Results</h2>
        
        <h2 class="title is-5">HunyuanVideo</h2>
        <div class="container is-max-desktop has-text-centered">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-t2i0">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/hy_tesla.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-t2i1">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/hy_girl-tesla.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-t2i1">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/hy_baseball.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        <br>

        <h2 class="title is-5">CogVideoX-2B</h2>
        <div class="container is-max-desktop has-text-centered">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-t2i0">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/cog_balloon.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-t2i1">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/cog_corgi.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-t2i1">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/cog_jr-train.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        <br>

        <h2 class="title is-5">Open-Sora v1.2</h2>
        <div class="container is-max-desktop has-text-centered">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-t2i0">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/os_cake.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-t2i1">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/os_car-blue.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item item-t2i1">
              <video autoplay muted loop playsinline class="interpolation-video">
                <source src="./static/videos/os_stairs.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>

        <div class="content has-text-justified">
          <p>
            <br>The experimental results reveals significant improvements in video enhancement across all tested models. When examining the HunyuanVideo results, the enhanced version demonstrates superior contrast and clarity, particularly noticeable in the more realistic wheels and charging station. 
          </p>
        </div>

        <h2 class="title is-4">Temperature Analysis</h2>
        <div class="container is-max-desktop">
          <video class="video" autoplay controls muted loop playsinline>
            <source src="./static/videos/temperature.mp4" type="video/mp4">
          </video>
          <p>
            The increase of temperature leads to more details and creativity. However, extreme high temperatures indicates illogical content and video distortion.
          </p>
        </div>
      </div>
    </div>
  </div>

  <!-- <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">        
        <div class="content has-text-justified">
          <h2 class="title is-4">Quantitive Results</h2>
          <div class="content has-text-centered">
            <img src="./static/images/eval.png" style="width: 40%;"><br>
          </div>
        </div>
      </div>
    </div>
  </div> -->
</section>

<section class="hero is-small">
  <div class="container is-max-desktop hero-body">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related works</h2>
        <div class="content has-text-justified">
          <p>
            <li>
              Brooks, Tim, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, Clarence Ng, Ricky Wang and Aditya Ramesh. “Video generation models as world simulators.“ OpenAI Research (2024).
            </li>
            <li>
              Kong, Weijie, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jia-Liang Xiong, Xin Li, Bo Wu, Jianwei Zhang, Kathrina Wu, Qin Lin, Junkun Yuan, Yanxin Long, Aladdin Wang, Andong Wang, Changlin Li, Duojun Huang, Fan Yang, Hao Tan, Hongmei Wang, Jacob Song, Jiawang Bai, Jianbing Wu, Jinbao Xue, Joey Wang, Kai Wang, Mengyang Liu, Peng-Yu Li, Shuai Li, Weiyan Wang, Wenqing Yu, Xi Deng, Yang Li, Yi Chen, Yutao Cui, Yuanbo Peng, Zhen Yu, Zhiyu He, Zhiyong Xu, Zixiang Zhou, Zunnan Xu, Yang-Dan Tao, Qinglin Lu, Songtao Liu, Daquan Zhou, Hongfa Wang, Yong Yang, Di Wang, Yuhong Liu, Jie Jiang and Caesar Zhong. “HunyuanVideo: A Systematic Framework For Large Video Generative Models.” (2024).
            </li>
            <li>
              Yang, Zhuoyi, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, Da Yin, Xiaotao Gu, Yuxuan Zhang, Weihan Wang, Yean Cheng, Ting Liu, Bin Xu, Yuxiao Dong and Jie Tang. “CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer.” ArXiv abs/2408.06072 (2024).
            </li>
            <li>
              Wang, Pei-Hsin, Sheng-Iou Hsieh, Shih-Chieh Chang, Yu-Ting Chen, Jia-Yu Pan, Wei Wei and Da-Chang Juan. “Contextual Temperature for Language Modeling.” ArXiv abs/2012.13575 (2019).
            </li>
            <li>
              Wang, Chi, Susan Liu and Ahmed Hassan Awadallah. “Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference.” ArXiv abs/2303.04673 (2023).
            </li>
            <li>
              Renze, Matthew and Erhan Guven. “The Effect of Sampling Temperature on Problem Solving in Large Language Models.” ArXiv abs/2402.05201 (2024).
            </li>
          </p>
        </div>
      </div>
    </div>
  </div>

</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title"><a id="bibtex">BibTeX</a></h2>
    <pre><code>@misc{luo2025enhanceavideobettergeneratedvideo,
      title={V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models}, 
      author={Yang Luo and Xuanlei Zhao and Mengzhao Chen and Kaipeng Zhang and Wenqi Shao and Kai Wang and Zhangyang Wang and Yang You},
      year={2025},
      eprint={2502.07508},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2502.07508}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a href="https://nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<script src="juxtapose/js/juxtapose.js"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js"></script>    

</body>
</html>
