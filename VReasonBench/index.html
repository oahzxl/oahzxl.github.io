<!DOCTYPE html>
<html>
<meta property='og:title' content='V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models'/>
<meta property='og:description' content='V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models'/>
<meta property='og:url' content='https://oahzxl.github.io/VReasonBench/'/>
<meta property='og:image:width' content='1200' />
<meta property='og:image:height' content='663' />
<!-- TYPE BELOW IS PROBABLY: 'website' or 'article' or look on https://ogp.me/#types -->
<meta property="og:type" content='website'/>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models">
  <meta name="keywords" content="V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models</title>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/tab_gallery.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="juxtapose/css/juxtapose.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/magnifier.js"></script>
  <link href="https://fonts.cdnfonts.com/css/menlo" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/image_card_fader.css">
  <link rel="stylesheet" href="./static/css/image_card_slider.css">
  <link rel="stylesheet"
        href="https://fonts.googleapis.com/css?family=Patrick+Hand|Google+Sans|Noto+Sans|Castoro|Lato|Open+Sans&effect=shadow-multiple|emboss|3d"> 
  <!-- <link rel="icon" href="./static/images/pyramid.png" type="image/x-icon"> -->
  <!-- <link rel="shortcut icon" href="./static/images/pyramid.png" type="image/x-icon"> -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/tab_gallery.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="juxtapose/css/juxtapose.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/magnifier.js"></script>
  <link href="https://fonts.cdnfonts.com/css/menlo" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/image_card_fader.css">
  <link rel="stylesheet" href="./static/css/image_card_slider.css">
</head>

<style>
  @import url('https://fonts.cdnfonts.com/css/menlo');

  .video-table td, .video-table th {
    padding-top: 2px;
    padding-bottom: 2px;
    padding-left: 4px;
    padding-right: 4px;
    font-weight: normal;
  }
  .first-col {
    width: 7%;
    vertical-align: middle;
  }
  .other-col {
    width: 31%;
  }
  body {
    font-family: "Lato", sans-serif;
    font-size: 1.1em;
  }
  .title.is-3 {
    font-weight: 900;
    font-size: 2.0rem;
  }
  .title.is-4 {
    font-weight: 700;
    font-size: 1.7rem;
  }
  .custom-emoji {
    width: 1em;
    height: 1em;
    display: inline-block;
    background-image: url('./static/images/pyramid.png');
    background-size: cover;
    vertical-align: middle;
    line-height: 1;
  }

  .interpolation-video {
    width: 100%;
    height: auto;
    border-radius: 5px;
  }
  
  .results-carousel .item {
    margin: 10px;
    overflow: hidden;
    padding: 20px;
    font-size: 0;
  }
  
  .results-carousel video {
    margin: 0;
  }

  /* 修复图片下方的细线间隙 */
  .content img {
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  /* 调整section间距 */
  .section {
    padding: 2rem 1.5rem;
  }

  /* 调整section标题大小 */
  .title.is-2 {
    font-size: 1.75rem;
    margin-bottom: 1.5rem;
  }

  /* 视频网格布局 */
  .simulation-grid {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 30px;
    margin-top: 2rem;
  }

  .simulation-item {
    display: flex;
    flex-direction: column;
    align-items: center;
  }

  .simulation-item video {
    width: 100%;
    height: auto;
    border-radius: 8px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    background-color: #f5f5f5;
  }

  .simulation-label {
    margin-top: 12px;
    font-size: 1rem;
    font-weight: 500;
    text-align: center;
    color: #333;
  }

  /* 响应式设计 */
  @media screen and (max-width: 1024px) {
    .simulation-grid {
      grid-template-columns: repeat(2, 1fr);
      gap: 20px;
    }
  }

  @media screen and (max-width: 768px) {
    .simulation-grid {
      grid-template-columns: 1fr;
      gap: 20px;
    }
  }

</style>


<body>
  <section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <br><br>
          <h1 class="title is-2 publication-title" style="font-size: 1.95rem">
            V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models
          </h1>
          

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yangluo7.github.io/" target="_blank">Yang Luo</a><sup>1,2,*</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://oahzxl.github.io/" target="_blank">Xuanlei Zhao</a><sup>1,*</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://baijiong-lin.github.io/" target="_blank">Baijiong Lin</a><sup>2,3*</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://advocate99.github.io/" target="_blank">Lingting Zhu</a><sup>2,4</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://github.com/LiyaoTang" target="_blank">Liyao Tang</a><sup>2,5</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://liuricky.github.io/" target="_blank">Yuqi Liu</a><sup>2,6</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://www.yingcong.me/" target="_blank">Ying-Cong Chen</a><sup>3</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="http://thesouthfrog.com/about.me/" target="_blank">Shengju Qian</a><sup>2,†</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=2Z1GJ50AAAAJ&hl=en" target="_blank">Xin Wang</a><sup>2</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://www.comp.nus.edu.sg/~youy/" target="_blank">Yang You</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National University of Singapore&nbsp;&nbsp;</span>
            <span class="author-block"><sup>2</sup>LIGHTSPEED&nbsp;&nbsp;</span>
            <span class="author-block"><sup>3</sup>The Hong Kong University of Science and Technology (Guangzhou)&nbsp;&nbsp;</span>
            <span class="author-block"><sup>4</sup>The University of Hong Kong&nbsp;&nbsp;</span>
            <span class="author-block"><sup>5</sup>The University of Sydney</span>
            <span class="author-block"><sup>6</sup>The Chinese University of Hong Kong</span>
          </div>

          <!-- <div class="is-size-5 publication-authors">
            {xuanlei, kai.wang, youy}@comp.nus.edu.sg&nbsp;&nbsp;&nbsp;jin509@purdue.edu
          </div> -->

          <div class="is-size-5 publication-authors">
            (* indicates equal contribution, † indicates corresponding author)
          </div>

          <!-- <div class="is-size-5 publication-venue">
            in XXX
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/yangluo7/V-ReasonBench" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- paper -->
              <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- doc -->
              <!-- <span class="link-block">
                <a href="https://github.com/NUS-HPC-AI-Lab/VideoSys/blob/master/docs/pab.md" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-book"></i>
                  </span>
                  <span>Doc</span>
                  </a>
              </span> -->
              <!-- twitter -->
              <!-- <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-twitter"></i>
                  </span>
                  <span>Twitter</span>
                </a>
              </span> -->
              <!-- bibtex -->
              <span class="link-block">
                <a href="#bibtex"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-obp"></i>
                  </span>
                  <span>BibTex</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-2" style="text-align: center;">Abstract</h2>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            We introduce V-ReasonBench, a benchmark designed to assess video reasoning across four key dimensions: structured problem-solving, spatial cognition, pattern-based inference, and physical dynamics. The benchmark is built from both synthetic and real-world image sequences and provides a diverse set of answer-verifiable tasks that are reproducible, scalable, and unambiguous. Evaluations of six state-of-the-art video models reveal clear dimension-wise differences, with strong variation in structured, spatial, pattern-based, and physical reasoning. We further compare video models with strong image models, analyze common hallucination behaviors, and study how video duration affects Chain-of-Frames reasoning. Overall, V-ReasonBench offers a unified and reproducible framework for measuring video reasoning and aims to support the development of models with more reliable, human-aligned reasoning skills.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/pipeline.png" class="interpolation-image" style="width: 100%; height: auto;"/>
        </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-2" style="text-align: center;">Results of Recent Video Generation Models</h2>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            Model-level overall and per-dimension performance on V-ReasonBench. A pass@5 score for each model is calculated within each dimension and presented accordingly (left). Summary of V-ReasonBench performance across video models (right). The figure illustrates how six video generation models perform on 13 reasoning tasks, with scores rescaled within each dimension to enable direct comparison.
          </p>
        </div>
        <div style="text-align: center; display: flex; justify-content: center; align-items: flex-start; gap: 20px;">
          <img src="./static/images/result1.png" class="interpolation-image" style="width: 48%; height: auto;"/>
          <img src="./static/images/result2.png" class="interpolation-image" style="width: 48%; height: auto;"/>
        </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-2" style="text-align: center;">Reasoning Task Coverage and Video Totals</h2>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            Overview of reasoning dimensions, tasks, and number of videos in V-ReasonBench. Each instance is an initial–final image pair, with each model generating five videos for pass@5 evaluation.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/statistics.png" class="interpolation-image" style="width: 60%; height: auto;"/>
        </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-2" style="text-align: center;">Precise and Reliable Evaluation</h2>
        <div style="text-align: center;">
          <img src="./static/images/VLM.png" class="interpolation-image" style="width: 90%; height: auto;"/>
        </div>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            Example failure case from several reasoning tasks illustrating the limitations of VLM-based automatic evaluation. Although the underlying rule is simple, the VLM incorrectly assesses the model's output due to difficulties in recognizing small grid cells and fine structural differences.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/human_prefer.png" class="interpolation-image" style="width: 75%; height: auto;"/>
        </div>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            Human–alignment validation of our benchmark's scoring pipeline. Each point compares binary Pass/Unpass decisions from the automatic evaluation with human judgments across four reasoning categories.
          </p>
        </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2" style="text-align: center;">Generated Videos -- Structured Problem-Solving: Tic-Tac-Toe</h2>
    <div class="simulation-grid">
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/sora_ttt.mp4"></video>
        <p class="simulation-label">Sora-2</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/veo_ttt.mp4"></video>
        <p class="simulation-label">Veo-3.1</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/hailuo_ttt.mp4"></video>
        <p class="simulation-label">Hailuo-02</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/kling_ttt.mp4"></video>
        <p class="simulation-label">Kling-2.5-Turbo-Pro</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/vidu_ttt.mp4"></video>
        <p class="simulation-label">Vidu-Q2</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/seed_ttt.mp4"></video>
        <p class="simulation-label">Seedance-1.0-Lite</p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2" style="text-align: center;">Generated Videos -- Spatial Cognition: Color Connection</h2>
    <div class="simulation-grid">
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/sora_connect.mp4"></video>
        <p class="simulation-label">Sora-2</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/veo_connect.mp4"></video>
        <p class="simulation-label">Veo-3.1</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/hailuo_connect.mp4"></video>
        <p class="simulation-label">Hailuo-02</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/kling_connect.mp4"></video>
        <p class="simulation-label">Kling-2.5-Turbo-Pro</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/vidu_connect.mp4"></video>
        <p class="simulation-label">Vidu-Q2</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/seed_connect.mp4"></video>
        <p class="simulation-label">Seedance-1.0-Lite</p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2" style="text-align: center;">Generated Videos -- Pattern-based Inference: Rule Following</h2>
    <div class="simulation-grid">
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/sora_rule.mp4"></video>
        <p class="simulation-label">Sora-2</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/veo_rule.mp4"></video>
        <p class="simulation-label">Veo-3.1</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/hailuo_rule.mp4"></video>
        <p class="simulation-label">Hailuo-02</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/kling_rule.mp4"></video>
        <p class="simulation-label">Kling-2.5-Turbo-Pro</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/vidu_rule.mp4"></video>
        <p class="simulation-label">Vidu-Q2</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/seed_rule.mp4"></video>
        <p class="simulation-label">Seedance-1.0-Lite</p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2" style="text-align: center;">Generated Videos -- Physical Dynamics: Block Sliding</h2>
    <div class="simulation-grid">
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/sora_block.mp4"></video>
        <p class="simulation-label">Sora-2</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/veo_block.mp4"></video>
        <p class="simulation-label">Veo-3.1</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/hailuo_block.mp4"></video>
        <p class="simulation-label">Hailuo-02</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/kling_block.mp4"></video>
        <p class="simulation-label">Kling-2.5-Turbo-Pro</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/vidu_block.mp4"></video>
        <p class="simulation-label">Vidu-Q2</p>
      </div>
      <div class="simulation-item">
        <video controls loop muted autoplay playsinline preload="auto" src="./static/videos/seed_block.mp4"></video>
        <p class="simulation-label">Seedance-1.0-Lite</p>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-2" style="text-align: center;">Reasoning Patterns in Video Generation</h2>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            Example from the Seedance-1.0-Lite and Vidu-Q2 models on the Tic-Tac-Toe task. The model introduces additional decorative patterns across the mirrored axis, illustrating its tendency to enrich visual appearance rather than preserve original geometric form.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/reason_pattern.png" class="interpolation-image" style="width: 90%; height: auto;"/>
        </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-2" style="text-align: center;">Influence of Duration on Video Reasoning</h2>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            Effect of video duration on reasoning outcomes of Sora2 in the Chain-of-Frame setting. Each row compares model generations with different "thinking" durations for tasks such as Sudoku and Rule Following. Although longer durations correspond to longer reasoning processes (4s vs. 8s, 5s vs. 10s), the resulting outputs do not consistently improve.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/CoF_time.png" class="interpolation-image" style="width: 100%; height: auto;"/>
        </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-2" style="text-align: center;">Video Models vs. Image Models</h2>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            Comparison between Veo-3.1 (video model) and NanoBanana (image model) on Block Sliding (left) and Code Execution (right). Video models leverage the Chain-of-Frames process to simulate intermediate states, enabling stronger performance on tasks that require causal or temporal reasoning, although intermediate transitions may still appear physically inconsistent. Image models provide clean and stable outputs and excel at text-based tasks such as code execution, but their single-frame reasoning limits their ability to capture the underlying physical dynamics.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/IvsV.png" class="interpolation-image" style="width: 90%; height: auto;"/>
        </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-2" style="text-align: center;">Hallucination in Video Reasoning</h2>
        <div class="content has-text-justified">
          <p class="abstract-text" style="font-size: 0.95rem; line-height: 1.5;">
            Examples of hallucinations in the Chain-of-Frame reasoning process. Each row shows a trajectory from input to output, where the final frame is correct but intermediate frames display unrealistic or physically inconsistent transitions.
          </p>
        </div>
        <div style="text-align: center;">
          <img src="./static/images/hallucination.png" class="interpolation-image" style="width: 90%; height: auto;"/>
        </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title"><a id="bibtex">BibTeX</a></h2>
    <pre><code>@misc{luo2025enhanceavideobettergeneratedvideo,
      title={V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models}, 
      author={Yang Luo and Xuanlei Zhao and Mengzhao Chen and Kaipeng Zhang and Wenqi Shao and Kai Wang and Zhangyang Wang and Yang You},
      year={2025},
      eprint={2502.07508},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2502.07508}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a href="https://nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<script src="juxtapose/js/juxtapose.js"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js"></script>    

</body>
</html>
